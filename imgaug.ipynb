{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from files import *\n",
    "from pascal_voc_writer import Writer\n",
    "#from files import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=cv2.imread('./OD/image/image_001.jpg')\n",
    "#print(img)\n",
    " \n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_anntation(xml_file: str):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    bounding_box_list = []\n",
    "\n",
    "    file_name = root.find('filename').text\n",
    "    for obj in root.iter('object'):\n",
    "\n",
    "        object_label = obj.find(\"name\").text\n",
    "        for box in obj.findall(\"bndbox\"):\n",
    "            x_min = int(box.find(\"xmin\").text)\n",
    "            y_min = int(box.find(\"ymin\").text)\n",
    "            x_max = int(box.find(\"xmax\").text)\n",
    "            y_max = int(box.find(\"ymax\").text)\n",
    "\n",
    "        bounding_box = [object_label, x_min, y_min, x_max, y_max]\n",
    "        bounding_box_list.append(bounding_box)\n",
    "\n",
    "    return bounding_box_list, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_dataset(dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    ldir = 'C:/project/data3/'\n",
    "    for file in listdir(dir):\n",
    "      \n",
    "        if 'jpg' in file.lower() or 'png' in file.lower():\n",
    "            images.append(cv2.imread(dir + file, 1))\n",
    "            annotation_file = file.replace(file.split('.')[-1], 'xml')\n",
    "            bounding_box_list, file_name = read_anntation(ldir + annotation_file)\n",
    "            annotations.append((bounding_box_list, annotation_file, file_name))\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a9f0a0dc47be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#해당 인덱스의 바운딩 박스\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#바운딩 박스 정보를 저장할 리스트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'annotations' is not defined"
     ]
    }
   ],
   "source": [
    "#imgaug의 글로벌 RNG(무작위 제어)의 seed 설정\n",
    "ia.seed(1)\n",
    "\n",
    "#r경로 지정\n",
    "dir = 'C:/project/data3/'\n",
    "dir1 = 'C:/project/data2/'\n",
    "#경로에 있는 이미지와 xml 정보를 읽음\n",
    "images, annotations = read_train_dataset(dir)\n",
    "\n",
    "#이미지의 개수만큼 반복\n",
    "for idx in range(len(images)):\n",
    "    \n",
    "    #해당 인덱스의 이미지\n",
    "    image = images[idx]\n",
    "    #해당 인덱스의 바운딩 박스\n",
    "    boxes = annotations[idx][0]\n",
    "\n",
    "    #바운딩 박스 정보를 저장할 리스트\n",
    "    ia_bounding_boxes = []\n",
    "    for box in boxes:\n",
    "        #바운딩 박스들을 리스트에 저장\n",
    "        ia_bounding_boxes.append(ia.BoundingBox(x1=box[1], y1=box[2], x2=box[3], y2=box[4]))\n",
    "    #바운딩 박스들을 이미지 위에 그림\n",
    "    bbs = ia.BoundingBoxesOnImage(ia_bounding_boxes, shape=image.shape)\n",
    "\n",
    "    #크기 지정\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Resize(0.7)\n",
    "        #iaa.Multiply((1.5,1.5))\n",
    "        #iaa.Affine(\n",
    "            #shear=(-15,15)\n",
    "            #rotate=45\n",
    "        #)\n",
    "    ])\n",
    "\n",
    "    #이미지를 지정한 크기로 변경\n",
    "    seq_det = seq.to_deterministic()\n",
    "\n",
    "    #이미지와 바운딩 박스의 크기 변경\n",
    "    image_aug = seq_det.augment_images([image])[0]\n",
    "    bbs_aug = seq_det.augment_bounding_boxes([bbs])[0]\n",
    "\n",
    "    #크기를 변경하기 전 이미지와변경한 후 이미지를 비교\n",
    "    for i in range(len(bbs.bounding_boxes)):\n",
    "        before = bbs.bounding_boxes[i]\n",
    "        after = bbs_aug.bounding_boxes[i]\n",
    "        print(\"BB %d: (%.4f, %.4f, %.4f, %.4f) -> (%.4f, %.4f, %.4f, %.4f)\" % (\n",
    "            i,\n",
    "            before.x1, before.y1, before.x2, before.y2,\n",
    "            after.x1, after.y1, after.x2, after.y2)\n",
    "        )\n",
    "        \n",
    "    image_before = bbs.draw_on_image(image, size=5)\n",
    "    image_after = bbs_aug.draw_on_image(image_aug, size=5, color=[0, 0, 255])\n",
    "\n",
    "    #cv2.imshow('image_before', cv2.resize(image_before, (380, 640)))\n",
    "    #cv2.imshow('image_after', cv2.resize(image_after, (380, 640)))\n",
    "    \n",
    "    cv2.imwrite\n",
    "    \n",
    "    #변경하기 전 이미지와 변경한 후 이미지를 plot으로 표현하여 출력\n",
    "    fig = plt.figure()\n",
    "    rows = 1\n",
    "    cols = 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    aimage = fig.add_subplot(rows, cols, 1)\n",
    "    plt.imshow(image_before)\n",
    "    \n",
    "    bimage = fig.add_subplot(rows, cols, 2)\n",
    "    plt.imshow(image_after)\n",
    "    plt.show()\n",
    "    \n",
    "    image_aug = seq_det.augment_images([image])[0]\n",
    "    bbs_aug = seq_det.augment_bounding_boxes([bbs])[0]\n",
    "\n",
    "    new_image_file = dir1 + '0.7resize_' + annotations[idx][2]\n",
    "    cv2.imwrite(new_image_file, image_aug)\n",
    "\n",
    "    h, w = np.shape(image_aug)[0:2]\n",
    "    voc_writer = Writer(new_image_file, w, h)\n",
    "\n",
    "    for i in range(len(bbs_aug.bounding_boxes)):\n",
    "        bb_box = bbs_aug.bounding_boxes[i]\n",
    "        voc_writer.addObject(boxes[i][0], int(bb_box.x1), int(bb_box.y1), int(bb_box.x2), int(bb_box.y2))\n",
    "\n",
    "    voc_writer.save(dir1 + '0.7resize_' + annotations[idx][1])\n",
    "    \n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
