{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from darkflow.net.build import TFNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import exit\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "%config inlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing cfg/lp_detect.cfg\n",
      "Loading None ...\n",
      "Finished in 0.0s\n",
      "\n",
      "Building net ...\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\build.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\ops\\baseop.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\ops\\baseop.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\ops\\baseop.py:84: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\ops\\simple.py:106: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\ops\\convolution.py:28: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "ksizes is deprecated, use sizes instead\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 250)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.7 usage\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\build.py:132: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "cfg/lp_detect.cfg loss hyper-parameters:\n",
      "\tH       = 19\n",
      "\tW       = 19\n",
      "\tbox     = 5\n",
      "\tclasses = 45\n",
      "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\yolov2\\train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Building cfg/lp_detect.cfg loss\n",
      "WARNING:tensorflow:From G:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\yolov2\\train.py:107: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "INFO:tensorflow:Summary name cfg/lp_detect.cfg loss is illegal; using cfg/lp_detect.cfg_loss instead.\n",
      "Building cfg/lp_detect.cfg train op\n",
      "WARNING:tensorflow:From c:\\users\\bjyou\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\bjyou\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test/1/ckpt/checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1808e1cf82d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#tensorflow에서 darkflow 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtfnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mtfnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\build.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, FLAGS, darknet)\u001b[0m\n\u001b[0;32m     74\u001b[0m                         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_meta_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \t\tself.say('Finished in {}s\\n'.format(\n\u001b[0;32m     78\u001b[0m \t\t\ttime.time() - start))\n",
      "\u001b[1;32mG:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\build.py\u001b[0m in \u001b[0;36msetup_meta_ops\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m \t\tself.saver = tf.train.Saver(tf.global_variables(), \n\u001b[0;32m    150\u001b[0m \t\t\tmax_to_keep = self.FLAGS.keep)\n\u001b[1;32m--> 151\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_ckpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\LASIK\\LASIK_team4_Sejong\\Object_Detection\\darkflow\\net\\help.py\u001b[0m in \u001b[0;36mload_from_ckpt\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_from_ckpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# load lastest ckpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'checkpoint'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mlast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mload_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test/1/ckpt/checkpoint'"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "options = {\n",
    "    'model' : 'cfg/lp_detect.cfg',\n",
    "    'backup' : 'test/1/ckpt/',\n",
    "    #'load' : 28979,\n",
    "     #이전 학습 가중치를 이어서 학습(-1은 마지막 save를 불러옴)\n",
    "    'load' : -1,\n",
    "    #데이터셋의 전체 크기를 batch만큼 나눔\n",
    "    'batch': 4,\n",
    "    #학습의 횟수\n",
    "    'epoch': 1,\n",
    "    #gpu 사용 여부\n",
    "    'gpu' : 0.7,\n",
    "    'train' : True,\n",
    "    # learning rate\n",
    "    'lr' : 0.00001,\n",
    "    #annotation의 위치\n",
    "    'annotation': 'test/training/annotations/',\n",
    "    #dataset의 위치\n",
    "    'dataset' : 'test/training/',\n",
    "    'labels': '../labels.txt'\n",
    "}\n",
    "\n",
    "#tensorflow에서 darkflow 사용\n",
    "tfnet = TFNet(options)\n",
    "\n",
    "tfnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행\n",
    "options = {\n",
    "    \"model\" : 'cfg/lp_detect.cfg',\n",
    "   # 'load' : 'bin/yolo.weights',\n",
    "    'backup' : './test/1/ckpt/',\n",
    "    'load' : -1,#43441,\n",
    "    #confidence가 threshold보다 높을 경우 바운딩박스를 수용하겠다는 의미\n",
    "    'threshold' : 0.1,\n",
    "    'gpu' : 0.8,\n",
    "    'labels': '../labels.txt'\n",
    "}\n",
    "\n",
    "tfnet = TFNet(options)\n",
    "#tfnet.load_from_ckpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-777897ce0e79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#BGR 사진을 RGB 사진으로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#json형태로 결과 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#이미지 파일을 color로 읽음\n",
    "img = cv2.imread('test/training/image_739.jpg', cv2.IMREAD_COLOR)\n",
    "img1= img\n",
    "\n",
    "#BGR 사진을 RGB 사진으로 변환\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#json형태로 결과 출력\n",
    "results = tfnet.return_predict(img)\n",
    "print((results))\n",
    "\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "#plot으로 원본 이미지 출력\n",
    "fig = plt.figure(figsize=(19, 12)) \n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "\n",
    "#이미지 3차원 행렬(y축, x축, 바로 색을 표현하는 BGR)\n",
    "img.shape\n",
    "\n",
    "#랜덤한 색으로 추출된 바운딩 박스와 라벨 표시\n",
    "resultimg = copy.deepcopy(img)\n",
    "colors = [tuple(255*np.random.rand(3)) for _ in range(1000)]\n",
    "for color, result in zip(colors, results):\n",
    "    t1 = (result['topleft']['x'], result['topleft']['y'])\n",
    "    br = (result['bottomright']['x'], result['bottomright']['y'])\n",
    "    label = result['label']\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    print(confidence,t1,br)\n",
    "    crop_img = img[t1[1]:br[1], t1[0]:br[0]]\n",
    "    plt.imshow(crop_img)\n",
    "    plt.show()\n",
    "\n",
    "    resultimg = cv2.rectangle(resultimg, t1, br, color, 2)\n",
    "    resultimg = cv2.putText(resultimg, label, t1, cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,0), 2)\n",
    "\n",
    "#plot으로 결과가 표시된 이미지 출력\n",
    "fig = plt.figure(figsize=(19, 12)) \n",
    "plt.imshow(resultimg)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'license', 'confidence': 0.034519, 'topleft': {'x': 2, 'y': 559}, 'bottomright': {'x': 6, 'y': 586}}\n",
      "(2, 559) (6, 586)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "print((results[index]))\n",
    "t1 = (results[index]['topleft']['x'], results[index]['topleft']['y'])\n",
    "br = (results[index]['bottomright']['x'], results[index]['bottomright']['y'])\n",
    "print(t1,br)\n",
    "crop_img = img[t1[1]:br[1], t1[0]:br[0]]\n",
    "plt.imshow(crop_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"c:/project/data/result/result.jpg\",crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
